{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "#Model\n",
    "import xgboost as xgb\n",
    "#Sklearn\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,RepeatedStratifiedKFold,cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,auc,roc_auc_score,roc_curve,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Others\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import optuna\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the Work Path\n",
    "warnings.filterwarnings ('ignore')\n",
    "#Work Path\n",
    "os.chdir(\"C:/Users/A/Desktop/Paper_0_Hydrogel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc']) # 这里设定了 index 个数要和列表长度一致\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 4175)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>267.28</td>\n",
       "      <td>8.352500</td>\n",
       "      <td>20.0734</td>\n",
       "      <td>33.3526</td>\n",
       "      <td>19.8921</td>\n",
       "      <td>36.9899</td>\n",
       "      <td>0.627294</td>\n",
       "      <td>1.042269</td>\n",
       "      <td>0.621628</td>\n",
       "      <td>1.155934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.407895</td>\n",
       "      <td>17.966397</td>\n",
       "      <td>8.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>244.23</td>\n",
       "      <td>8.421724</td>\n",
       "      <td>17.9656</td>\n",
       "      <td>30.5854</td>\n",
       "      <td>17.5454</td>\n",
       "      <td>33.3290</td>\n",
       "      <td>0.619503</td>\n",
       "      <td>1.054669</td>\n",
       "      <td>0.605014</td>\n",
       "      <td>1.149276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>14.808251</td>\n",
       "      <td>7.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>243.25</td>\n",
       "      <td>8.108333</td>\n",
       "      <td>18.2722</td>\n",
       "      <td>31.3599</td>\n",
       "      <td>18.0966</td>\n",
       "      <td>34.6179</td>\n",
       "      <td>0.609073</td>\n",
       "      <td>1.045330</td>\n",
       "      <td>0.603220</td>\n",
       "      <td>1.153930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>14.808251</td>\n",
       "      <td>7.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>283.28</td>\n",
       "      <td>8.584242</td>\n",
       "      <td>20.7882</td>\n",
       "      <td>34.6799</td>\n",
       "      <td>20.3466</td>\n",
       "      <td>38.1993</td>\n",
       "      <td>0.629945</td>\n",
       "      <td>1.050906</td>\n",
       "      <td>0.616564</td>\n",
       "      <td>1.157555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>19.586399</td>\n",
       "      <td>10.257197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>251.28</td>\n",
       "      <td>8.105806</td>\n",
       "      <td>19.3586</td>\n",
       "      <td>32.0253</td>\n",
       "      <td>19.4376</td>\n",
       "      <td>35.7805</td>\n",
       "      <td>0.624471</td>\n",
       "      <td>1.033074</td>\n",
       "      <td>0.627019</td>\n",
       "      <td>1.154210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>17.259745</td>\n",
       "      <td>8.115820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                MW       AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "ID                                                                           \n",
       "Ma_2019_A   267.28  8.352500  20.0734  33.3526  19.8921  36.9899  0.627294   \n",
       "Ma_2019_U   244.23  8.421724  17.9656  30.5854  17.5454  33.3290  0.619503   \n",
       "Ma_2019_C   243.25  8.108333  18.2722  31.3599  18.0966  34.6179  0.609073   \n",
       "Ma_2019_G   283.28  8.584242  20.7882  34.6799  20.3466  38.1993  0.629945   \n",
       "Ma_2019_dA  251.28  8.105806  19.3586  32.0253  19.4376  35.7805  0.624471   \n",
       "\n",
       "                  Me        Mp        Mi  ...  s1_numAroBonds  s2_numAroBonds  \\\n",
       "ID                                        ...                                   \n",
       "Ma_2019_A   1.042269  0.621628  1.155934  ...             0.0             0.0   \n",
       "Ma_2019_U   1.054669  0.605014  1.149276  ...             0.0             0.0   \n",
       "Ma_2019_C   1.045330  0.603220  1.153930  ...             0.0             0.0   \n",
       "Ma_2019_G   1.050906  0.616564  1.157555  ...             0.0             0.0   \n",
       "Ma_2019_dA  1.033074  0.627019  1.154210  ...             0.0             0.0   \n",
       "\n",
       "            s3_numAroBonds  s4_numAroBonds  s34_size  s34_relSize  s34_phSize  \\\n",
       "ID                                                                              \n",
       "Ma_2019_A              0.0            10.0      16.0     0.842105        7.75   \n",
       "Ma_2019_U              0.0             0.0      14.0     0.823529        6.75   \n",
       "Ma_2019_C              0.0             0.0      14.0     0.823529        6.75   \n",
       "Ma_2019_G              0.0             5.0      17.0     0.850000        8.75   \n",
       "Ma_2019_dA             0.0            10.0      15.0     0.833333        7.00   \n",
       "\n",
       "            s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "ID                                                       \n",
       "Ma_2019_A        0.407895     17.966397        8.618182  \n",
       "Ma_2019_U        0.397059     14.808251        7.026700  \n",
       "Ma_2019_C        0.397059     14.808251        7.026700  \n",
       "Ma_2019_G        0.437500     19.586399       10.257197  \n",
       "Ma_2019_dA       0.388889     17.259745        8.115820  \n",
       "\n",
       "[5 rows x 4175 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "ML_data= pd.read_csv(\"./Original data/ML_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data= pd.read_csv(\"./Original data/X_NAomit_data.csv\",header=0,index_col=0)\n",
    "Raw_data = pd.read_csv('./Original data/raw_data.csv',index_col=0)\n",
    "Raw_data['Gelability']=np.where(Raw_data['Gelability']=='Gelable', 1, 0)\n",
    "#original data(descriptors= 4175）\n",
    "print(X_NAomit_data.shape)\n",
    "X_NAomit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATS3p</th>\n",
       "      <th>SM10_AEA(dm)</th>\n",
       "      <th>GATS7s</th>\n",
       "      <th>F07[N-O]</th>\n",
       "      <th>VE1sign_Dz(v)</th>\n",
       "      <th>VE3sign_D/Dt</th>\n",
       "      <th>P_VSA_charge_4</th>\n",
       "      <th>CATS2D_09_DA</th>\n",
       "      <th>B09[O-O]</th>\n",
       "      <th>CATS2D_06_DL</th>\n",
       "      <th>...</th>\n",
       "      <th>MATS2m</th>\n",
       "      <th>MATS2p</th>\n",
       "      <th>GATS6i</th>\n",
       "      <th>P_VSA_charge_2</th>\n",
       "      <th>Eig03_AEA(ed)</th>\n",
       "      <th>CATS2D_05_DA</th>\n",
       "      <th>GATS2p</th>\n",
       "      <th>C-016</th>\n",
       "      <th>s2_pathLength</th>\n",
       "      <th>GATS8i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>0.223067</td>\n",
       "      <td>0.382490</td>\n",
       "      <td>0.390779</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339202</td>\n",
       "      <td>0.433674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136148</td>\n",
       "      <td>0.791478</td>\n",
       "      <td>0.070041</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.580423</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.586479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>0.218409</td>\n",
       "      <td>0.270850</td>\n",
       "      <td>0.589845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>0.770077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028067</td>\n",
       "      <td>0.316380</td>\n",
       "      <td>0.138782</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.200950</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.711020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>0.189242</td>\n",
       "      <td>0.270850</td>\n",
       "      <td>0.462449</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.081578</td>\n",
       "      <td>0.770077</td>\n",
       "      <td>0.359389</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157809</td>\n",
       "      <td>0.441757</td>\n",
       "      <td>0.327739</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.200950</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.667729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.485155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>0.307924</td>\n",
       "      <td>0.390516</td>\n",
       "      <td>0.365302</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.259153</td>\n",
       "      <td>0.508232</td>\n",
       "      <td>0.359389</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224020</td>\n",
       "      <td>0.631157</td>\n",
       "      <td>0.262950</td>\n",
       "      <td>0.373931</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.484050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.607829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>0.277926</td>\n",
       "      <td>0.290988</td>\n",
       "      <td>0.582334</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.404032</td>\n",
       "      <td>0.457316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230461</td>\n",
       "      <td>0.794139</td>\n",
       "      <td>0.231586</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.536421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.658417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              MATS3p  SM10_AEA(dm)    GATS7s  F07[N-O]  VE1sign_Dz(v)  \\\n",
       "ID                                                                      \n",
       "Ma_2019_A   0.223067      0.382490  0.390779  0.500000       0.339202   \n",
       "Ma_2019_U   0.218409      0.270850  0.589845  0.000000       0.097243   \n",
       "Ma_2019_C   0.189242      0.270850  0.462449  0.166667       0.081578   \n",
       "Ma_2019_G   0.307924      0.390516  0.365302  0.500000       0.259153   \n",
       "Ma_2019_dA  0.277926      0.290988  0.582334  0.166667       0.404032   \n",
       "\n",
       "            VE3sign_D/Dt  P_VSA_charge_4  CATS2D_09_DA  B09[O-O]  \\\n",
       "ID                                                                 \n",
       "Ma_2019_A       0.433674        0.000000           0.4       0.0   \n",
       "Ma_2019_U       0.770077        0.000000           0.2       1.0   \n",
       "Ma_2019_C       0.770077        0.359389           0.2       0.0   \n",
       "Ma_2019_G       0.508232        0.359389           0.6       1.0   \n",
       "Ma_2019_dA      0.457316        0.000000           0.4       0.0   \n",
       "\n",
       "            CATS2D_06_DL  ...    MATS2m    MATS2p    GATS6i  P_VSA_charge_2  \\\n",
       "ID                        ...                                                 \n",
       "Ma_2019_A           0.00  ...  0.136148  0.791478  0.070041        0.015761   \n",
       "Ma_2019_U           0.25  ...  0.028067  0.316380  0.138782        0.384100   \n",
       "Ma_2019_C           0.25  ...  0.157809  0.441757  0.327739        0.025930   \n",
       "Ma_2019_G           0.00  ...  0.224020  0.631157  0.262950        0.373931   \n",
       "Ma_2019_dA          0.25  ...  0.230461  0.794139  0.231586        0.015761   \n",
       "\n",
       "            Eig03_AEA(ed)  CATS2D_05_DA    GATS2p  C-016  s2_pathLength  \\\n",
       "ID                                                                        \n",
       "Ma_2019_A        0.580423      0.500000  0.304895    0.0       0.090909   \n",
       "Ma_2019_U        0.200950      0.500000  0.711020    1.0       0.090909   \n",
       "Ma_2019_C        0.200950      0.500000  0.667729    1.0       0.090909   \n",
       "Ma_2019_G        0.587700      0.666667  0.484050    0.0       0.090909   \n",
       "Ma_2019_dA       0.536421      0.000000  0.242784    0.0       0.151515   \n",
       "\n",
       "              GATS8i  \n",
       "ID                    \n",
       "Ma_2019_A   0.586479  \n",
       "Ma_2019_U   0.000000  \n",
       "Ma_2019_C   0.485155  \n",
       "Ma_2019_G   0.607829  \n",
       "Ma_2019_dA  0.658417  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data after feature selection (descriptors= 64）\n",
    "print(ML_data.shape)\n",
    "ML_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X_test_NAomit=np.array(X_NAomit_data)\n",
    "X_test_ML=np.array(ML_data)\n",
    "y=Raw_data['Gelability'].values\n",
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.014766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.015074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.655102</td>\n",
       "      <td>0.015993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.022896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.020388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.634476  0.014766\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.669811  0.015074\n",
       "Precision       0.655102  0.015993\n",
       "Recall          0.710714  0.022896\n",
       "Roc_auc         0.691531  0.020388"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X_test_NAomit,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.638667</td>\n",
       "      <td>0.015374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.667694</td>\n",
       "      <td>0.014479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.669162</td>\n",
       "      <td>0.016666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.692143</td>\n",
       "      <td>0.022529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.721259</td>\n",
       "      <td>0.016294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.638667  0.015374\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.667694  0.014479\n",
       "Precision       0.669162  0.016666\n",
       "Recall          0.692143  0.022529\n",
       "Roc_auc         0.721259  0.016294"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2 （40 descriptors）\n",
    "Model2_clf=clf\n",
    "Model2_clf.fit(X_test_ML, y)\n",
    "#Model2\n",
    "Model2=Model_results(Model2_clf,X_test_ML,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-14 07:33:53,804]\u001b[0m A new study created in memory with name: no-name-83701ce0-ed38-48b1-a535-4c829353a636\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:33:55,085]\u001b[0m Trial 0 finished with value: 0.6268571428571428 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.6268571428571428.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:33:55,992]\u001b[0m Trial 1 finished with value: 0.5985714285714285 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.6268571428571428.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:33:57,303]\u001b[0m Trial 2 finished with value: 0.6271428571428572 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 2 with value: 0.6271428571428572.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:33:58,584]\u001b[0m Trial 3 finished with value: 0.6041904761904762 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 2 with value: 0.6271428571428572.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:33:59,432]\u001b[0m Trial 4 finished with value: 0.6396190476190476 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 4 with value: 0.6396190476190476.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:01,239]\u001b[0m Trial 5 finished with value: 0.5842857142857142 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 4 with value: 0.6396190476190476.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:02,235]\u001b[0m Trial 6 finished with value: 0.6452380952380952 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 6 with value: 0.6452380952380952.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:02,758]\u001b[0m Trial 7 finished with value: 0.6254285714285714 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 6 with value: 0.6452380952380952.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:03,086]\u001b[0m Trial 8 finished with value: 0.6548571428571429 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 8 with value: 0.6548571428571429.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:03,655]\u001b[0m Trial 9 finished with value: 0.644095238095238 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 8 with value: 0.6548571428571429.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:03,858]\u001b[0m Trial 10 finished with value: 0.5941904761904762 and parameters: {'lambda': 5.790132527437195, 'alpha': 0.025043968115100592, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.1901, 'n_estimators': 57}. Best is trial 8 with value: 0.6548571428571429.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:04,736]\u001b[0m Trial 11 finished with value: 0.6608571428571429 and parameters: {'lambda': 0.032961671871006855, 'alpha': 0.043812245346487144, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1401, 'n_estimators': 373}. Best is trial 11 with value: 0.6608571428571429.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:05,458]\u001b[0m Trial 12 finished with value: 0.6567619047619049 and parameters: {'lambda': 0.02491353701899208, 'alpha': 0.03404799435343261, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.14509999999999998, 'n_estimators': 321}. Best is trial 11 with value: 0.6608571428571429.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:06,268]\u001b[0m Trial 13 finished with value: 0.6454285714285715 and parameters: {'lambda': 0.038590705671310774, 'alpha': 0.05567342974400736, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 339}. Best is trial 11 with value: 0.6608571428571429.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:07,049]\u001b[0m Trial 14 finished with value: 0.6371428571428572 and parameters: {'lambda': 0.0012140452982167488, 'alpha': 0.010215573929742552, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 338}. Best is trial 11 with value: 0.6608571428571429.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:07,622]\u001b[0m Trial 15 finished with value: 0.6609523809523808 and parameters: {'lambda': 0.03677076350027389, 'alpha': 0.13339647538791952, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 246}. Best is trial 15 with value: 0.6609523809523808.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:08,129]\u001b[0m Trial 16 finished with value: 0.6433333333333334 and parameters: {'lambda': 0.004931808890264009, 'alpha': 0.16609303037529946, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.1101, 'n_estimators': 208}. Best is trial 15 with value: 0.6609523809523808.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:08,926]\u001b[0m Trial 17 finished with value: 0.6567619047619047 and parameters: {'lambda': 0.0746750278011609, 'alpha': 0.08546577364899868, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1701, 'n_estimators': 454}. Best is trial 15 with value: 0.6609523809523808.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:10,107]\u001b[0m Trial 18 finished with value: 0.6623809523809524 and parameters: {'lambda': 2.1003048098635637, 'alpha': 0.009911019475327826, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 559}. Best is trial 18 with value: 0.6623809523809524.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:11,959]\u001b[0m Trial 19 finished with value: 0.6535238095238095 and parameters: {'lambda': 9.591321307007483, 'alpha': 0.008516278982570248, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1251, 'n_estimators': 930}. Best is trial 18 with value: 0.6623809523809524.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:13,382]\u001b[0m Trial 20 finished with value: 0.6356190476190476 and parameters: {'lambda': 2.5132520362548596, 'alpha': 0.001292874909845673, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.050100000000000006, 'n_estimators': 598}. Best is trial 18 with value: 0.6623809523809524.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:14,253]\u001b[0m Trial 21 finished with value: 0.6425714285714286 and parameters: {'lambda': 0.7087036620195014, 'alpha': 0.010266297482473544, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 411}. Best is trial 18 with value: 0.6623809523809524.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:14,803]\u001b[0m Trial 22 finished with value: 0.654952380952381 and parameters: {'lambda': 0.0813426966198401, 'alpha': 0.1746311044100556, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.1701, 'n_estimators': 265}. Best is trial 18 with value: 0.6623809523809524.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:16,011]\u001b[0m Trial 23 finished with value: 0.6669523809523809 and parameters: {'lambda': 0.39554681010366227, 'alpha': 0.0028017436972920438, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1251, 'n_estimators': 689}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:17,430]\u001b[0m Trial 24 finished with value: 0.6594285714285715 and parameters: {'lambda': 2.763233094269281, 'alpha': 0.0038112741520838966, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 744}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:18,373]\u001b[0m Trial 25 finished with value: 0.6596190476190477 and parameters: {'lambda': 0.42633435402014297, 'alpha': 0.0029705090298029857, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1251, 'n_estimators': 531}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:19,826]\u001b[0m Trial 26 finished with value: 0.6563809523809523 and parameters: {'lambda': 1.8719484708781509, 'alpha': 0.013542538480404584, 'colsample_bytree': 0.4, 'subsample': 0.6000000000000001, 'learning_rate': 0.0651, 'n_estimators': 705}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:21,457]\u001b[0m Trial 27 finished with value: 0.6412380952380953 and parameters: {'lambda': 0.9471308557417807, 'alpha': 0.002175055077335732, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1051, 'n_estimators': 913}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:22,485]\u001b[0m Trial 28 finished with value: 0.6607619047619049 and parameters: {'lambda': 0.34265963641158714, 'alpha': 0.005964943448827902, 'colsample_bytree': 0.8, 'subsample': 0.7000000000000001, 'learning_rate': 0.1601, 'n_estimators': 590}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:23,748]\u001b[0m Trial 29 finished with value: 0.6480952380952381 and parameters: {'lambda': 0.15015202749142031, 'alpha': 0.7297885974341056, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.0801, 'n_estimators': 663}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:25,505]\u001b[0m Trial 30 finished with value: 0.6609523809523811 and parameters: {'lambda': 4.199875829741965, 'alpha': 0.0010057216538091605, 'colsample_bytree': 0.6000000000000001, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 844}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:27,302]\u001b[0m Trial 31 finished with value: 0.6554285714285715 and parameters: {'lambda': 4.8748562040737, 'alpha': 0.0013376440969893834, 'colsample_bytree': 0.6000000000000001, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 828}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:31,806]\u001b[0m Trial 32 finished with value: 0.6566666666666667 and parameters: {'lambda': 5.134941704643616, 'alpha': 0.0023030870744294453, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 745}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:35,312]\u001b[0m Trial 33 finished with value: 0.6552380952380952 and parameters: {'lambda': 0.15223774665722659, 'alpha': 0.0010414717877183974, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.1101, 'n_estimators': 979}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:39,188]\u001b[0m Trial 34 finished with value: 0.649904761904762 and parameters: {'lambda': 1.725731460382352, 'alpha': 0.016334877443344446, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0951, 'n_estimators': 849}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:41,299]\u001b[0m Trial 35 finished with value: 0.6424761904761905 and parameters: {'lambda': 3.333597293228305, 'alpha': 0.005852007587529048, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.1301, 'n_estimators': 509}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:45,371]\u001b[0m Trial 36 finished with value: 0.6411428571428571 and parameters: {'lambda': 9.557482957348375, 'alpha': 0.10879788308936203, 'colsample_bytree': 0.3, 'subsample': 0.7000000000000001, 'learning_rate': 0.15009999999999998, 'n_estimators': 773}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:47,517]\u001b[0m Trial 37 finished with value: 0.623904761904762 and parameters: {'lambda': 1.2414645782458593, 'alpha': 8.861629685772453, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1701, 'n_estimators': 705}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:49,965]\u001b[0m Trial 38 finished with value: 0.648 and parameters: {'lambda': 0.2584996760015814, 'alpha': 0.39559009459131417, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 571}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:54,196]\u001b[0m Trial 39 finished with value: 0.6222857142857143 and parameters: {'lambda': 0.5285065985610683, 'alpha': 1.6519698923047093, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0751, 'n_estimators': 882}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:56,592]\u001b[0m Trial 40 finished with value: 0.6483809523809524 and parameters: {'lambda': 1.036694312393886, 'alpha': 0.0033770652365990883, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.0901, 'n_estimators': 504}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:58,354]\u001b[0m Trial 41 finished with value: 0.6624761904761906 and parameters: {'lambda': 0.044985467280732876, 'alpha': 0.046876892274430614, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 388}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:34:59,573]\u001b[0m Trial 42 finished with value: 0.6521904761904761 and parameters: {'lambda': 0.016303932281777418, 'alpha': 0.06486318948181218, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 415}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:01,502]\u001b[0m Trial 43 finished with value: 0.6537142857142857 and parameters: {'lambda': 0.053657114790454534, 'alpha': 0.020688912244531173, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.11510000000000001, 'n_estimators': 624}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:02,188]\u001b[0m Trial 44 finished with value: 0.6125714285714285 and parameters: {'lambda': 0.1340290216031097, 'alpha': 0.1566613887861763, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 97}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:03,492]\u001b[0m Trial 45 finished with value: 0.643904761904762 and parameters: {'lambda': 0.009363115653935427, 'alpha': 0.005482279922549288, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.1201, 'n_estimators': 237}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:04,372]\u001b[0m Trial 46 finished with value: 0.6577142857142857 and parameters: {'lambda': 0.047551341472818205, 'alpha': 0.0020206131700439265, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1601, 'n_estimators': 170}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:05,964]\u001b[0m Trial 47 finished with value: 0.6452380952380953 and parameters: {'lambda': 0.021225774660087494, 'alpha': 0.047508918001390635, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.1051, 'n_estimators': 383}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:07,074]\u001b[0m Trial 48 finished with value: 0.6496190476190474 and parameters: {'lambda': 0.03135206110710554, 'alpha': 0.23365443531404081, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 291}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:08,618]\u001b[0m Trial 49 finished with value: 0.6539047619047619 and parameters: {'lambda': 0.10577326588736904, 'alpha': 0.029518299829384843, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.18009999999999998, 'n_estimators': 471}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:11,377]\u001b[0m Trial 50 finished with value: 0.634 and parameters: {'lambda': 0.2188691399256252, 'alpha': 0.45399100667524417, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1351, 'n_estimators': 801}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:12,962]\u001b[0m Trial 51 finished with value: 0.6610476190476191 and parameters: {'lambda': 0.031682549204679694, 'alpha': 0.037664487898751486, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1401, 'n_estimators': 369}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:13,901]\u001b[0m Trial 52 finished with value: 0.6607619047619048 and parameters: {'lambda': 0.07470255591839378, 'alpha': 0.07991608335108072, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 219}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:15,536]\u001b[0m Trial 53 finished with value: 0.6583809523809525 and parameters: {'lambda': 0.015009172434002703, 'alpha': 0.11654479935730282, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.15009999999999998, 'n_estimators': 370}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:17,027]\u001b[0m Trial 54 finished with value: 0.651047619047619 and parameters: {'lambda': 0.027637835860281835, 'alpha': 0.03551845541601185, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 323}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:19,435]\u001b[0m Trial 55 finished with value: 0.6455238095238096 and parameters: {'lambda': 0.009409942885534933, 'alpha': 0.020961961681509846, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 548}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:21,181]\u001b[0m Trial 56 finished with value: 0.6495238095238095 and parameters: {'lambda': 0.004205256264559074, 'alpha': 0.008926995335037716, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1101, 'n_estimators': 482}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:22,329]\u001b[0m Trial 57 finished with value: 0.656952380952381 and parameters: {'lambda': 0.04174457460764687, 'alpha': 0.01323839452402867, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1251, 'n_estimators': 433}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:24,458]\u001b[0m Trial 58 finished with value: 0.6520952380952382 and parameters: {'lambda': 0.06317574168205588, 'alpha': 0.0010034077761119319, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.1351, 'n_estimators': 690}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:26,727]\u001b[0m Trial 59 finished with value: 0.6507619047619048 and parameters: {'lambda': 1.9712697682934068, 'alpha': 0.0015583835067665278, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.08510000000000001, 'n_estimators': 640}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:28,218]\u001b[0m Trial 60 finished with value: 0.6325714285714286 and parameters: {'lambda': 3.3251003077013426, 'alpha': 0.0026792507779236628, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.10010000000000001, 'n_estimators': 274}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:29,720]\u001b[0m Trial 61 finished with value: 0.6539047619047619 and parameters: {'lambda': 0.03008055479873984, 'alpha': 0.046114879777730634, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1401, 'n_estimators': 377}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:30,834]\u001b[0m Trial 62 finished with value: 0.6581904761904761 and parameters: {'lambda': 0.09478189430740822, 'alpha': 0.0350797583051863, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 305}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:32,080]\u001b[0m Trial 63 finished with value: 0.663809523809524 and parameters: {'lambda': 0.03593363139993918, 'alpha': 0.07577795431103157, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1601, 'n_estimators': 363}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:33,443]\u001b[0m Trial 64 finished with value: 0.6524761904761905 and parameters: {'lambda': 0.013587580767700247, 'alpha': 0.0688120543384151, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1601, 'n_estimators': 350}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:33,804]\u001b[0m Trial 65 finished with value: 0.6407619047619048 and parameters: {'lambda': 0.019743306392673285, 'alpha': 0.22606621508207536, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.18009999999999998, 'n_estimators': 125}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:35,532]\u001b[0m Trial 66 finished with value: 0.6421904761904762 and parameters: {'lambda': 7.383435441281536, 'alpha': 0.13924735435080093, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.15009999999999998, 'n_estimators': 402}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:38,651]\u001b[0m Trial 67 finished with value: 0.6438095238095238 and parameters: {'lambda': 0.0020791955626078325, 'alpha': 0.09915546857528099, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 983}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:39,503]\u001b[0m Trial 68 finished with value: 0.6625714285714287 and parameters: {'lambda': 0.03933283846464265, 'alpha': 0.004621483928422759, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1651, 'n_estimators': 249}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:40,610]\u001b[0m Trial 69 finished with value: 0.6567619047619049 and parameters: {'lambda': 0.05112412628475363, 'alpha': 0.004746449458825323, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1651, 'n_estimators': 349}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:41,944]\u001b[0m Trial 70 finished with value: 0.6555238095238096 and parameters: {'lambda': 0.10608387455835115, 'alpha': 0.007699690319993537, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.18009999999999998, 'n_estimators': 454}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:43,021]\u001b[0m Trial 71 finished with value: 0.6661904761904763 and parameters: {'lambda': 0.03579443282679834, 'alpha': 0.015884557299083602, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1551, 'n_estimators': 253}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:43,880]\u001b[0m Trial 72 finished with value: 0.6438095238095238 and parameters: {'lambda': 0.038696895298117935, 'alpha': 0.012311278455750259, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1551, 'n_estimators': 179}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:44,748]\u001b[0m Trial 73 finished with value: 0.6594285714285714 and parameters: {'lambda': 0.06538749237664962, 'alpha': 0.01943634870873962, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1751, 'n_estimators': 204}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:45,803]\u001b[0m Trial 74 finished with value: 0.6637142857142858 and parameters: {'lambda': 0.022622621946305987, 'alpha': 0.0036500469265255053, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1951, 'n_estimators': 303}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:46,778]\u001b[0m Trial 75 finished with value: 0.6579047619047619 and parameters: {'lambda': 0.024511620127634054, 'alpha': 0.007145942012007491, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1951, 'n_estimators': 261}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:47,888]\u001b[0m Trial 76 finished with value: 0.6653333333333334 and parameters: {'lambda': 0.0225382029847921, 'alpha': 0.0036847714556209315, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1851, 'n_estimators': 282}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:49,095]\u001b[0m Trial 77 finished with value: 0.6498095238095237 and parameters: {'lambda': 0.00631188816342632, 'alpha': 0.004358972660737023, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1901, 'n_estimators': 309}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:49,781]\u001b[0m Trial 78 finished with value: 0.6607619047619048 and parameters: {'lambda': 0.013195372621752105, 'alpha': 0.003465170984234345, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1851, 'n_estimators': 217}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:50,348]\u001b[0m Trial 79 finished with value: 0.6554285714285715 and parameters: {'lambda': 0.010043345295189413, 'alpha': 0.002580184830276131, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1901, 'n_estimators': 250}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:51,715]\u001b[0m Trial 80 finished with value: 0.6636190476190477 and parameters: {'lambda': 0.021971806352023848, 'alpha': 0.0064012250408397395, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1651, 'n_estimators': 290}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:53,254]\u001b[0m Trial 81 finished with value: 0.6482857142857142 and parameters: {'lambda': 0.022355303026907202, 'alpha': 0.010020204959057033, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1701, 'n_estimators': 298}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:55,698]\u001b[0m Trial 82 finished with value: 0.6609523809523811 and parameters: {'lambda': 0.04010999513326522, 'alpha': 0.0069291448382585346, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1651, 'n_estimators': 328}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:57,288]\u001b[0m Trial 83 finished with value: 0.6666666666666667 and parameters: {'lambda': 0.017635438873653903, 'alpha': 0.005171499875791115, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1751, 'n_estimators': 278}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:58,410]\u001b[0m Trial 84 finished with value: 0.6624761904761906 and parameters: {'lambda': 0.017660695090165046, 'alpha': 0.001830150768505133, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1751, 'n_estimators': 268}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:59,142]\u001b[0m Trial 85 finished with value: 0.6611428571428571 and parameters: {'lambda': 0.01994733638158736, 'alpha': 0.0015325245223134166, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1751, 'n_estimators': 190}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:35:59,754]\u001b[0m Trial 86 finished with value: 0.6597142857142857 and parameters: {'lambda': 0.006362034192191643, 'alpha': 0.0019383758326622926, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:00,782]\u001b[0m Trial 87 finished with value: 0.6605714285714286 and parameters: {'lambda': 0.01189475265913138, 'alpha': 0.004165531523562008, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1851, 'n_estimators': 226}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:01,526]\u001b[0m Trial 88 finished with value: 0.6609523809523811 and parameters: {'lambda': 0.008416541584198503, 'alpha': 0.003075396407821543, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 278}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:02,496]\u001b[0m Trial 89 finished with value: 0.6610476190476191 and parameters: {'lambda': 0.01572599795466237, 'alpha': 0.005288860040004479, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1651, 'n_estimators': 241}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:03,532]\u001b[0m Trial 90 finished with value: 0.6468571428571428 and parameters: {'lambda': 0.026301427802842517, 'alpha': 0.002490681304305035, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1851, 'n_estimators': 265}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:04,688]\u001b[0m Trial 91 finished with value: 0.6636190476190477 and parameters: {'lambda': 0.01725366466573098, 'alpha': 0.0036521753739400848, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 342}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:05,985]\u001b[0m Trial 92 finished with value: 0.6496190476190477 and parameters: {'lambda': 0.032774351768312664, 'alpha': 0.0037932032345691963, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1601, 'n_estimators': 289}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:07,156]\u001b[0m Trial 93 finished with value: 0.6468571428571428 and parameters: {'lambda': 0.017575780114167737, 'alpha': 0.006456380314966377, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1701, 'n_estimators': 353}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:08,385]\u001b[0m Trial 94 finished with value: 0.6539047619047619 and parameters: {'lambda': 0.0458951348134732, 'alpha': 0.004590942121346708, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 314}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:09,083]\u001b[0m Trial 95 finished with value: 0.6581904761904762 and parameters: {'lambda': 0.024047944331523016, 'alpha': 0.0017100321647404403, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1751, 'n_estimators': 160}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:10,319]\u001b[0m Trial 96 finished with value: 0.6523809523809524 and parameters: {'lambda': 0.03519271810576947, 'alpha': 0.016765231421200528, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1651, 'n_estimators': 397}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:11,100]\u001b[0m Trial 97 finished with value: 0.6567619047619049 and parameters: {'lambda': 0.007496366535703364, 'alpha': 0.0012643451907963382, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.18009999999999998, 'n_estimators': 195}. Best is trial 23 with value: 0.6669523809523809.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:12,201]\u001b[0m Trial 98 finished with value: 0.6706666666666667 and parameters: {'lambda': 0.052739889359645756, 'alpha': 0.0030422324066177544, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 330}. Best is trial 98 with value: 0.6706666666666667.\u001b[0m\n",
      "\u001b[32m[I 2023-01-14 07:36:13,569]\u001b[0m Trial 99 finished with value: 0.6606666666666666 and parameters: {'lambda': 0.060275227798411504, 'alpha': 0.003385233172443351, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 331}. Best is trial 98 with value: 0.6706666666666667.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X_test_ML, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.052739889359645756, 'alpha': 0.0030422324066177544, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 330}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.650762</td>\n",
       "      <td>0.012548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.673582</td>\n",
       "      <td>0.014725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.682875</td>\n",
       "      <td>0.013735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.021824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.016605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.650762  0.012548\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.673582  0.014725\n",
       "Precision       0.682875  0.013735\n",
       "Recall          0.696429  0.021824\n",
       "Roc_auc         0.745867  0.016605"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model3\n",
    "Model3=Model_results(clf,X_test_ML,y,Cv_model)\n",
    "Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Recursive feature elimination\n",
    "min_features_to_select =5\n",
    "rfecv = RFECV(estimator=clf,step=1,cv=Cv_RFECV,scoring=\"accuracy\",min_features_to_select=min_features_to_select,n_jobs=8)\n",
    "rfecv.fit(X_test_ML,y)\n",
    "columns=Series(ML_data.columns.tolist())[rfecv.support_.tolist()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb=ML_data[columns]\n",
    "data_xgb.to_csv(\"./Results/data_xgb.csv\",sep=',')\n",
    "X_XGB=np.array(data_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_scores = len(rfecv.cv_results_[\"mean_test_score\"])\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Mean test accuracy\")\n",
    "plt.errorbar(\n",
    "    range(min_features_to_select, n_scores + min_features_to_select),\n",
    "    rfecv.cv_results_[\"mean_test_score\"],\n",
    "    yerr=rfecv.cv_results_[\"std_test_score\"],\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.704190</td>\n",
       "      <td>0.015589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.731079</td>\n",
       "      <td>0.014342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.723033</td>\n",
       "      <td>0.017179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.018838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.791029</td>\n",
       "      <td>0.015862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.704190  0.015589\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.731079  0.014342\n",
       "Precision       0.723033  0.017179\n",
       "Recall          0.757500  0.018838\n",
       "Roc_auc         0.791029  0.015862"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model4 （len(columns) descriptors）\n",
    "Model4_clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)\n",
    "Model4_clf.fit(X_XGB, y)\n",
    "#Model4\n",
    "Model4=Model_results(Model4_clf,X_XGB,y,Cv_model)\n",
    "Model4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model4_clf=Model4_clf.fit(X_XGB, y)\n",
    "#Saving the final model\n",
    "joblib.dump(Model4_clf, './Models/XGB.pkl')\n",
    "XGB= joblib.load(filename='./Models/XGB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATS3p</th>\n",
       "      <th>SM10_AEA(dm)</th>\n",
       "      <th>GATS7s</th>\n",
       "      <th>B09[O-O]</th>\n",
       "      <th>CATS2D_06_DL</th>\n",
       "      <th>P_VSA_charge_7</th>\n",
       "      <th>VE1sign_B(p)</th>\n",
       "      <th>MATS3m</th>\n",
       "      <th>P_VSA_LogP_5</th>\n",
       "      <th>P_VSA_LogP_4</th>\n",
       "      <th>Mv</th>\n",
       "      <th>MATS2m</th>\n",
       "      <th>MATS2p</th>\n",
       "      <th>CATS2D_05_DA</th>\n",
       "      <th>GATS2p</th>\n",
       "      <th>C-016</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>0.148099</td>\n",
       "      <td>0.279629</td>\n",
       "      <td>0.937287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.055154</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.630087</td>\n",
       "      <td>0.375852</td>\n",
       "      <td>0.294068</td>\n",
       "      <td>0.534972</td>\n",
       "      <td>0.369317</td>\n",
       "      <td>0.839555</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.120946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13463</th>\n",
       "      <td>0.167609</td>\n",
       "      <td>0.382490</td>\n",
       "      <td>0.371194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>0.577077</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.843058</td>\n",
       "      <td>-0.145355</td>\n",
       "      <td>0.534014</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.224814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39148</th>\n",
       "      <td>0.082452</td>\n",
       "      <td>0.442684</td>\n",
       "      <td>0.247689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.365425</td>\n",
       "      <td>-0.032536</td>\n",
       "      <td>0.522655</td>\n",
       "      <td>0.218782</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.386171</td>\n",
       "      <td>0.490001</td>\n",
       "      <td>1.437855</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.226505</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56328</th>\n",
       "      <td>0.345941</td>\n",
       "      <td>0.338437</td>\n",
       "      <td>0.498540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036314</td>\n",
       "      <td>0.555061</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.689307</td>\n",
       "      <td>0.185979</td>\n",
       "      <td>0.786846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67358</th>\n",
       "      <td>0.202511</td>\n",
       "      <td>0.471826</td>\n",
       "      <td>0.577994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352888</td>\n",
       "      <td>0.673856</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.322354</td>\n",
       "      <td>0.650332</td>\n",
       "      <td>0.151812</td>\n",
       "      <td>0.729538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.423568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MATS3p  SM10_AEA(dm)    GATS7s  B09[O-O]  CATS2D_06_DL  \\\n",
       "cid                                                               \n",
       "5273   0.148099      0.279629  0.937287       0.0          0.25   \n",
       "13463  0.167609      0.382490  0.371194       0.0          0.00   \n",
       "39148  0.082452      0.442684  0.247689       0.0          0.00   \n",
       "56328  0.345941      0.338437  0.498540       0.0          0.00   \n",
       "67358  0.202511      0.471826  0.577994       0.0          0.00   \n",
       "\n",
       "       P_VSA_charge_7  VE1sign_B(p)    MATS3m  P_VSA_LogP_5  P_VSA_LogP_4  \\\n",
       "cid                                                                         \n",
       "5273         0.055154      0.063176  0.630087      0.375852      0.294068   \n",
       "13463        0.000000      0.003349  0.577077      0.175482      0.415638   \n",
       "39148        0.365425     -0.032536  0.522655      0.218782      0.415638   \n",
       "56328        0.000000     -0.036314  0.555061      0.175482      0.415638   \n",
       "67358        0.000000      0.352888  0.673856      0.175482      0.322354   \n",
       "\n",
       "             Mv    MATS2m    MATS2p  CATS2D_05_DA    GATS2p  C-016  \n",
       "cid                                                                 \n",
       "5273   0.534972  0.369317  0.839555     -0.166667  0.120946    0.0  \n",
       "13463  0.843058 -0.145355  0.534014      0.166667  0.224814    0.0  \n",
       "39148  0.386171  0.490001  1.437855      0.500000 -0.226505    0.0  \n",
       "56328  0.689307  0.185979  0.786846      0.000000  0.189035    0.0  \n",
       "67358  0.650332  0.151812  0.729538      0.500000  0.423568    0.0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction of gelability\n",
    "X_test_dataframe=pd.read_csv(\"./Original data/X_test_data.csv\",sep=',',index_col=0)\n",
    "X_test_last=X_test_dataframe[data_xgb.columns.to_list()]\n",
    "X_test=np.array(X_test_last)\n",
    "X_test_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability of not gelable</th>\n",
       "      <th>Probability of gelable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.744965</td>\n",
       "      <td>0.255035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032582</td>\n",
       "      <td>0.967418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801961</td>\n",
       "      <td>0.198039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.384812</td>\n",
       "      <td>0.615188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.497980</td>\n",
       "      <td>0.502020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7252</th>\n",
       "      <td>0.734936</td>\n",
       "      <td>0.265064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7253</th>\n",
       "      <td>0.220765</td>\n",
       "      <td>0.779235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7254</th>\n",
       "      <td>0.240419</td>\n",
       "      <td>0.759581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7255</th>\n",
       "      <td>0.695719</td>\n",
       "      <td>0.304281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7256</th>\n",
       "      <td>0.876342</td>\n",
       "      <td>0.123658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7257 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Probability of not gelable  Probability of gelable\n",
       "0                       0.744965                0.255035\n",
       "1                       0.032582                0.967418\n",
       "2                       0.801961                0.198039\n",
       "3                       0.384812                0.615188\n",
       "4                       0.497980                0.502020\n",
       "...                          ...                     ...\n",
       "7252                    0.734936                0.265064\n",
       "7253                    0.220765                0.779235\n",
       "7254                    0.240419                0.759581\n",
       "7255                    0.695719                0.304281\n",
       "7256                    0.876342                0.123658\n",
       "\n",
       "[7257 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predicted_data=pd.DataFrame(XGB.predict_proba(X_test),columns=['Probability of not gelable','Probability of gelable'])\n",
    "\n",
    "Predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability of not gelable</th>\n",
       "      <th>Probability of gelable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5271957</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71302469</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.999398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122130330</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.999398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271955</th>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.999297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150667</th>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.999293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Probability of not gelable  Probability of gelable\n",
       "cid                                                          \n",
       "5271957                      0.000417                0.999583\n",
       "71302469                     0.000602                0.999398\n",
       "122130330                    0.000602                0.999398\n",
       "5271955                      0.000703                0.999297\n",
       "150667                       0.000707                0.999293"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted results\n",
    "Predicted_data=pd.DataFrame(XGB.predict_proba(X_test),columns=['Probability of not gelable','Probability of gelable'])\n",
    "Predicted_data.index=X_test_last.index\n",
    "Predicted_data.sort_values(by=\"Probability of gelable\" , inplace=True, ascending=False)\n",
    "Predicted_data.to_csv(\"./Results/XGB_predict_data.csv\",sep=',')\n",
    "Predicted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"8\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.638667</td>\n",
       "      <td>0.015374</td>\n",
       "      <td>0.650762</td>\n",
       "      <td>0.012548</td>\n",
       "      <td>0.704190</td>\n",
       "      <td>0.015589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.015074</td>\n",
       "      <td>0.667694</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>0.673582</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.731079</td>\n",
       "      <td>0.014342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.655102</td>\n",
       "      <td>0.015993</td>\n",
       "      <td>0.669162</td>\n",
       "      <td>0.016666</td>\n",
       "      <td>0.682875</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>0.723033</td>\n",
       "      <td>0.017179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.022896</td>\n",
       "      <td>0.692143</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.018838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.020388</td>\n",
       "      <td>0.721259</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.791029</td>\n",
       "      <td>0.015862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method           XGBoost                                                    \\\n",
       "Model            Model 1             Model 2             Model 3             \n",
       "Values              Mean        Se      Mean        Se      Mean        Se   \n",
       "Accuracy_test   0.634476  0.014766  0.638667  0.015374  0.650762  0.012548   \n",
       "Accuracy_train  0.978164  0.001539  0.978164  0.001539  0.978164  0.001539   \n",
       "F1 Score        0.669811  0.015074  0.667694  0.014479  0.673582  0.014725   \n",
       "Precision       0.655102  0.015993  0.669162  0.016666  0.682875  0.013735   \n",
       "Recall          0.710714  0.022896  0.692143  0.022529  0.696429  0.021824   \n",
       "Roc_auc         0.691531  0.020388  0.721259  0.016294  0.745867  0.016605   \n",
       "\n",
       "Method                              \n",
       "Model            Model 4            \n",
       "Values              Mean        Se  \n",
       "Accuracy_test   0.704190  0.015589  \n",
       "Accuracy_train  0.978164  0.001539  \n",
       "F1 Score        0.731079  0.014342  \n",
       "Precision       0.723033  0.017179  \n",
       "Recall          0.757500  0.018838  \n",
       "Roc_auc         0.791029  0.015862  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2,Model3,Model4],axis=1)\n",
    "Model_data.to_csv(\"./Results/XGB_model_data.csv\",sep=',')\n",
    "Model_data.columns = [['XGBoost']*8,['Model 1','Model 1', 'Model 2','Model 2', 'Model 3', 'Model 3', 'Model 4', 'Model 4'], ['Mean', 'Se', 'Mean', 'Se', 'Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv('./Results/XGB_model_data.csv',encoding='utf-8')\n",
    "#Read data：pd.read_csv('./Results/LR_model_data.csv',encoding='utf-8',header=[0,1,2])\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_VSA_LogP_4</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATS2p</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.002919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATS2m</th>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>0.003924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATS2D_05_DA</th>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATS2D_06_DL</th>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM10_AEA(dm)</th>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>0.004786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-016</th>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATS3m</th>\n",
       "      <td>0.012901</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.005387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GATS7s</th>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.002974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B09[O-O]</th>\n",
       "      <td>0.016141</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>0.004660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_VSA_charge_7</th>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.003927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_VSA_LogP_5</th>\n",
       "      <td>0.020549</td>\n",
       "      <td>0.017469</td>\n",
       "      <td>0.005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mv</th>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.004792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GATS2p</th>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.018205</td>\n",
       "      <td>0.005757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VE1sign_B(p)</th>\n",
       "      <td>0.049113</td>\n",
       "      <td>0.024133</td>\n",
       "      <td>0.007631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATS3p</th>\n",
       "      <td>0.069225</td>\n",
       "      <td>0.026893</td>\n",
       "      <td>0.008504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method           XGBoost                    \n",
       "Values              mean       std        se\n",
       "P_VSA_LogP_4    0.000014  0.003181  0.001006\n",
       "MATS2p          0.000282  0.009232  0.002919\n",
       "MATS2m          0.002873  0.012410  0.003924\n",
       "CATS2D_05_DA    0.003366  0.014335  0.004533\n",
       "CATS2D_06_DL    0.007746  0.012145  0.003840\n",
       "SM10_AEA(dm)    0.007873  0.015134  0.004786\n",
       "C-016           0.010887  0.005900  0.001866\n",
       "MATS3m          0.012901  0.017036  0.005387\n",
       "GATS7s          0.015183  0.009405  0.002974\n",
       "B09[O-O]        0.016141  0.014736  0.004660\n",
       "P_VSA_charge_7  0.016746  0.012417  0.003927\n",
       "P_VSA_LogP_5    0.020549  0.017469  0.005524\n",
       "Mv              0.021817  0.015154  0.004792\n",
       "GATS2p          0.039648  0.018205  0.005757\n",
       "VE1sign_B(p)    0.049113  0.024133  0.007631\n",
       "MATS3p          0.069225  0.026893  0.008504"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Importance\n",
    "XGB= joblib.load(filename='./Models/XGB.pkl')\n",
    "result = permutation_importance(\n",
    "    XGB, X_XGB, y, n_repeats=1000, random_state=0, n_jobs=2)\n",
    "clf2_importances = pd.Series(result.importances_mean, index= columns)\n",
    "importances_mean=pd.DataFrame(clf2_importances, index=columns)\n",
    "importances_std=pd.DataFrame(result.importances_std, index=columns)\n",
    "importances_se=pd.DataFrame(result.importances_std/math.sqrt(10), index=columns)\n",
    "importances_=pd.concat([importances_mean,importances_std,importances_se],axis=1)\n",
    "importances_.columns=[\"mean\",\"std\",\"se\"]\n",
    "Feature_importance=importances_.sort_values(by=\"mean\",ascending=True)\n",
    "Feature_importance.columns=[['XGBoost']*3,[\"mean\",\"std\",\"se\"]]\n",
    "Feature_importance.columns.names=['Method','Values']\n",
    "Feature_importance.to_csv('./Results/XGB_feature_importance.csv',encoding='utf-8')\n",
    "Feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrogel",
   "language": "python",
   "name": "hydrogel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac10202e3c764a95635a8e859710cdbe29cbdb013d40d51437c619046830f05c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
